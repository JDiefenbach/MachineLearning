---
title: "Predicting the Right Class of a Weight Lifting Exercise"
author: "J Diefenbach"
date: "December 16, 2015"
output: html_document
---

#Executive Summary#

In this small paper, we build a model for predicting the right class of performing a Unilateral Dumbbell Biceps Exercise in the WLE dataset from Qualitative Activity Recognition of Weight Lifting Exercises (Velloso, et al., 2013). The data is divided in 5 classes:

- A. According to the specification
- B. Throwing the elbows to the front
- C. Lifting the dumbbell only halfway
- D. Lowering the dumbbell only halfway
- E. Throwing the hips to the front

The final model we use for predicting the right class is a random forest model using a randomly selected subsample of size 1500 and 54 variables. The model has an expected out-of-bag error of 5.9% and an accuracy on the complete trainingset of 95%. On the test set it reaches a score of 18/20 (90%). 

---

#Analysis#

In this section we will describe the build up of the final prediction model.

**Exploratory Data Analysis**

The data in the trainingset consists of 19622 observations of 160 variables. Therefore, we will need to do some cleaning before we can start with the analysis. First of all, a number of variables have the 'NA' entry over 90% of the time. Only when a new window starts they contain an entry. In the test set, however, they also have an 'NA' entry, and therefore they will not be used as predictors in the final model.

Some variables in the dataset have little meaning when predicting the class of performance of the bicep curl exercise. These include the timestamp variables (3 in total), the window variables (new and num) and the X variable. When we exclude these from the dataset, we are left with a dataset containing 54 variables, of which one is the classe variable. A description of the different variables is given in table 1 of the appendix.

To get a sense of which of the variables are the most important predictors for the classe variable, we will start by training a random forest model with only a small random subsample (100 observations) of the data. Although we expect the accuracy to be low (in this case it is 59%), we can use the model to investigate the most important variables of the prediction. In table 2, we show the means per class of 5 of the most important variables: roll_belt, magnet_dumbbell_z, roll_dumbell, pitch_forearm and roll_forearm. 

When we look at table 2, we can indeed see why these variables are important in a prediction model. For example, the magnet_dumbbell_z mean for classe A is much lower than the other variables, and much higher for classe E. Although this table doesn't say anything about the variation of the variables, it is a good starting point for the analysis. 

We can show in a plot using only 2 variables how the prediction algorithm should work. In figure 1, we plot roll_belt on the x-axis and pitch_forearm on the y-axis. We colour the points according to the classe to which they belong. We can see, that for a number of combinations of the two variables we can predict to which classe they belong. There is for example a large cluster of classe E observations for a roll_belt greater than 125. Another example is that there are only classe A observations for a pitch_forearm lower than -30. Overall, the data, for these two variables, is nicely divided into different clusters, which should give confidence that we can find a prediction algorithm with good accuracy.

```{r, echo = FALSE, include = FALSE}
##Load packages and set the seed
library(caret)
library(dplyr)
set.seed(12345)

## Read the data
training <- read.csv("pml-training.csv", header = TRUE, na.strings = c("", NA))
testing <- read.csv("pml-testing.csv", header = TRUE)

## Subset to remove the NA entries
trainingNA <- training[,!is.na(training[1,])]
sel <-c(-1, -3:-7)
trainingUse <- trainingNA[,sel]
testNA <- testing[,!is.na(testing[1,])]
testingUse <- testNA[,sel]
```

**Prediction Model**

In the final prediction model, we will use the random forest method. A big advantage of this method is the accuracy of the prediction. Moreover, the cross-validation is internally estimated. A drawback of using a random forest model is the computational power needed, especially in a large dataset like this. Therefore, we will need to use a randomly selected subsample from the total dataset. The best tradeoff between computational power and accuracy is somewhere around a sample size of 1500 for the computer used (which is kind of an old model). The results presented will be with using this random sample.

In table 4, the results are presented for the random forest model with a randomly selected subsample of size 1500. The out-of-bag error estimate of the prediction, which is the expected out of sample error is 5.9%, which is acceptable. In table 5, the confusion matrix is given for the prediction model on the actual (total) trainingset. The accuracy is 95%, which is good. The difference between the expected out-of-bag error and the actual error of the model in the trainingset (5%) can be the result of overfitting the trainingset of size 1500. 

Using this prediction model on the test set gave a score of 18/20, which is equal to 90%. This is slightly lower than we would have expected by looking at the expected out-of-bag error, but nonetheless is an acceptable score.

**Appendix**

*Table 1: Structure of cleaned Weight Lifting Exercises Dataset*
``` {r, echo = FALSE}
## Structure of the dataset##
str(trainingUse)
```

*Table 2: Means per Class of 5 of the Most Important Variables in Small Sample Analysis*
```{r, echo = FALSE, include = FALSE}
## Sampling and training (exploratory data analysis purpose)
sample100 <- sample_n(trainingUse, 100, replace = FALSE)
modFit100 <- train(classe ~ ., data = sample100, method = "rf", prox = TRUE)
predict100 <- predict(modFit100, trainingUse) ##62%
```

``` {r, echo = FALSE, warning = FALSE}
## Putting the means of the variables in a table, divided by classe
class <- group_by(trainingUse, classe)
cols <- names(class[-54])
dots <- sapply(cols, function(x) substitute(mean(x), list(x = as.name(x))))
meanTable <- do.call(summarize, c(list(.data = class), dots))
select(meanTable, classe, roll_belt, magnet_dumbbell_z, roll_dumbbell, pitch_forearm, roll_forearm)
```

*Figure 1: Plot of pitch_forearm and roll_belt by classe*
``` {r, echo = FALSE}
##Plots
g <- ggplot(trainingUse, aes(roll_belt, pitch_forearm))
g + geom_point(aes(colour = trainingUse$classe))
```

*Table 3: Results of Random Forest Estimation*
``` {r, echo=FALSE}
sample1500 <- sample_n(trainingUse, 1500, replace = FALSE)
modFit1500 <- train(classe ~ ., data = sample1500, method = "rf", prox = TRUE)
predict1500 <- predict(modFit1500, trainingUse) ##95%
modFit1500$finalModel
```

*Table 4: Confusion Matrix of Final Model on Trainingset*
``` {r, echo = FALSE}
table(predict1500, trainingUse$classe) 
##varImp(modFit1500) ## roll_belt => pitch_forearm => roll_forearm => yaw_belt
```
